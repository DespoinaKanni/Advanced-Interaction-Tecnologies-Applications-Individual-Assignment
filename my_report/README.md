# Lesson: Advanced Interaction Technologies & Applications

### First and Last Name: Δέσποινα Καννή Ρεμπούλη
### University Registration Number: dpsd17042
### GitHub Personal Profile: https://github.com/DespoinaKanni
### Advanced Interaction Tecnologies & Applications Github Personal Repository: https://github.com/DespoinaKanni/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment

# Introduction

Το μάθημα κάνει μια εισαγωγή στο processing το οποίο είναι μια γλώσσα προγραμματισμού ανοικτού κώδικα και παράλληλα προγραμματιστικό περιβάλλον για ανθρώπους που θέλουν να προγραμματίσουν εικόνες, animation και ήχο. Στην συνέχεια, γίνεται εφαρμογή της κάμερας Kinect που ανιχνεύει την κίνηση. 

# Summary

Το μάθημα έχει 3 παραδοτέα εργασιών μέσω των οποίων γίνεται μια εκτεταμένη εισαγωγή σε θέματα απαιτήσεων χρήστη, σχεδίασης, πρωτοτυποποίησης και αξιολόγησης προηγμένων και φυσικών διεπαφών του χρήστη. Ακόμη, το εργαστήριο αφορά τον προγραμματισμό της Kinect με σκοπό την ανάπτυξη φυσικών διεπαφών όπως οι ανθρώπινες κινήσεις. Οι γλώσσες προγραμματισμού είναι η Processing με την βιβλιοθήκη (SimpleOpenNI library) και η C#. Μέσα από τα παραδοτέα γίνεται η μάθηση και η εξάσκηση του κώδικα. 


# 1st Deliverable

Η εργασία έγινε στους υπολογιστές της σχολής. 

**`Βήματα που πραγματοποίησα πριν ξεκινήσω τις εργασίες:`**

1. Συνδέθηκα στο GitΗub με τους κωδικούς μου.
2. Μπήκα στο GitHub Desktop, έβαλα τους κωδικούς του GitHub και συνδέθηκε με τον λογαριασμό μου. 
3. Από το GitHub Desktop έκανα clone το repository του Advanced Interaction Tecnologies & Applications και το αποθήκευσα μέσα στον φάκελο του processing.

## Video Capture

Για το πρώτο παραδοτέο έφτιαξα ένα νεό αρχείο και το αποθήκευσα μέσα στον φάκελο του video capture στο source. 
Στο αρχείο έφτιαξα στο preferences την διαδρομή ώστε να είναι στο φάκελο του processing στο data.  

Μπήκα στο *eclass* και άνοιξα το βιβλίο `Shiffman, Daniel - Learning Processing, Second Edition_ A Beginner's Guide to Progra.pdf`.
Βρήκα το παράδειγμα 16_1 και το αντέγραψα στο νέο άρχειο.

![Capture](https://user-images.githubusercontent.com/100956507/199835802-c4565bb6-0f5b-4325-9bcd-fed6de8c702d.PNG)

## Recorded Video

* `Άνοιξα τα έτοιμα παραδείγματα 16_4 και 16_5 από τα libraries και τα έτρεξα.` 

![video](https://user-images.githubusercontent.com/100956507/199837756-066e5f2d-cf8c-42cd-9e0e-c3e68d805b2d.PNG)

![video2](https://user-images.githubusercontent.com/100956507/199838205-f534bac5-fc7c-469b-a0fe-3e7865b24238.PNG)

* Βρήκα το excerise 16_2 μέσα από το βιβλίο και πάτησα το [link](https://processing.org/reference/libraries/video/Movie_speed_.html) που περιέχει.

![exersice](https://user-images.githubusercontent.com/100956507/199838714-a4013ecf-552c-4262-8fae-7caca9a54b5f.PNG)

* `Ο κώδικας από το παραπάνω link` 

![code](https://user-images.githubusercontent.com/100956507/199839741-bb5697b5-fbbb-4c5d-902d-48bbfe14823c.PNG)

* Προσάρμοσα τα παραδείγματα με τον κώδικα που με οδήγησε το link ώστε να μπορεί να παίζει το δικό μου βίντεο και να μπορώ να του αλλάζω την ταχύτητα με το ποντίκι.

* Βρήκα ένα βίντεο από το youtube και από την [ιστοσελίδα](https://y2mate.tools/en57ef) το κατέβασα. 
Έπειτα έφτιαξα έναν φάκελο μέσα στον φάκελο που είχα αποθηκεύσει το αρχείο μου και τον ονόμασα data. Εκεί αποθήκευσα το βίντεο. Τέλος έβαλα στον κώδικα το όνομα του βίντεο μου ώστε να μου το εμφανίζει.

## QR Code

* Άνοιξα το έτοιμο παράδειγμα 15_1 για να καταλάβω πως εμφανίζω εικόνες.

![imgparadeigma](https://user-images.githubusercontent.com/100956507/199845644-5d264076-eb5b-481b-8e27-8ada07b13894.PNG)

* Βρήκα μέσα από την [*βιβλιοθήκη*](https://shiffman.net/p5/qrcode-processing/) του qrcode τον κώδικα.

![librarycode](https://user-images.githubusercontent.com/100956507/199846545-320cd350-4954-40c2-adac-4a3146257332.PNG)

* Συνδύασα τους 2 κώδικες ώστε να εμφανίζεται στην οθόνη η εικόνα του qrcode και στην συνέχεια να την διαβάζει αυτόματα και να με οδηγεί κατευθείαν μέσα στο link.

* Το Qr Code το έφτιαξα από την [ιστοσελίδα](https://qr.io/?gclid=EAIaIQobChMItMOK7YWT-wIVT4KDBx0XhgRKEAAYASAAEgLAePD_BwE).

* Αποθήκευσα μέσα στο data την εικόνα του qr code.

## QR Code - Camera Read

Άνοιξα το έτοιμο παράδειγμα *`QrCodeExample`* και το αντέγραψα σε ένα δικό μου αρχείο. Έσβησα το έτοιμο `case f` και πρόσθεσα ένα δικό μου *`case k`*.
Πάτησα το play και μου άνοιξε η κάμερα, πλησίασα στην κάμερα του υπολογιστή την εικόνα του qr code μου και πάτησα το space μέχρι να μου την διαβάσει. Όταν μου την διάβασε πάτησα το γράμμα `k` και με έβγαλε στο προφιλ μου στο GitHub.

## Augmented Reality

Κατέβασα την βιβλιοθηκή **nyar4psg** από το processing (Java). Αντέγραψα τον φάκελο **data** από την βιβλιοθήκη και τον αποθήκευσα μέσα στο φάκελο που έχω την εργασία μου.
Άνοιξα το πάράδειγμα **SimpleLite**, κατέβασα μια εικόνα της επιλογής μου και την αποθήκευσα μέσα στον φάκελο data. Τέλος, προσάρμοσα στον κώδικα το όνομα της δικιάς μου είκονας. 
Στην συνέχεια άλλαξα το **path** και έβαλα το όνομα του δικού μου αρχείου με απότελεσμα να ανοίγει η κάμερα, να αναγνωρίζει το hiro και να εμφανίζει την εικόνα μου.

**`Από τα 2 hiro που είναι μέσα στον φάκελο data, αυτό που λειτουργεί για να εμφανίζεται η είκονα μου είναι το εξής:`**  

![320x240ABGR](https://user-images.githubusercontent.com/100956507/200048477-a62914cf-187e-4d9b-982d-61d2cb947b87.png)

*Γενικά επειδή η κάμερα δυσκολευόταν να ανοίξει χρειάστηκε να πατάω πολλές φορές το play και το pause του processing μέχρι να την εντοπίσει. Για να μου ανοίγει η κάμερα χωρίς πολλές δοκιμές σε κάποια παραδοτέα πρόσθεσα στον κώδικα `pipeline:autovideosrc`*

# 2nd Deliverable

## Background Removal

**`Για να βάλω είκονα στο background:`**

* Άνοιξα το έτοιμο [Example 16-12](http://learningprocessing.com/examples/chp16/example-16-12-BackgroundRemove) και το [Exercise 16-6](http://learningprocessing.com/exercises/chp16/exercise-16-06-greenscreen) από τα libraries και τα έτρεξα.

* Αντέγραψα και επεξεργάστηκα το Exercise 16-6 σε ένα νέο δικό μου αρχείο και το αποθήκευσα.

* Έφτιαξα έναν νεό φάκελο data όπου εκεί μέσα αποθήκευσα μια εικόνα από το διαδίκτυο.

### *`ΚΩΔΙΚΑΣ:`* 
άλλαξα και έβαλα στον κώδικα το *όνομα* της εικόνας μου. Πήγα στην φωτογραφία και κοίταξα στα properties, στις λεπτομέρειες, τις *διαστάσεις (πλάτος, ύψος)* της. Έβαλα τις διαστάσεις στο *size* ώστε η είκονα να εμφανίζεται ομοιόμορφη από πίσω μου.

Τέλος, 

1. έτρεξα το αρχείο και άνοιξε η κάμερα, 
2. έφυγα τελείως από το οπτικό πεδίο της κάμερας, 
3. πάτησα κλικ με το ποντίκι στο παράθυρο της κάμερας και έτσι εμφανίστηκε η είκονα. 
4. έπειτα μπήκα και εγώ στο οπτικό πεδίο της κάμερας και με έδειχνε μπροστά από την εικόνα. 

**`Για να βάλω video στο background:`**

* Κατέβασα ένα βίντεο από το Youtube από την [ιστοσελίδα](https://y2mate.tools/en57ef).

* Το αποθήκευσα σε ένα καινούργιο φάκελο data.

* Πήγα στο [Example 16-4](http://learningprocessing.com/examples/chp16/example-16-04-MoviePlayback) για να θυμηθώ πως εισάγουμε ένα βίντεο σε επανάληψη και προσάρμοσα τον κώδικα στον δικό μου.

`κώδικας:`

![code16-4](https://user-images.githubusercontent.com/100956507/205693785-8ede01e4-1bc7-4941-8b62-75cfcfc6eb71.PNG)


### *`ΚΩΔΙΚΑΣ:`* 
άλλαξα και έβαλα στον κώδικα το *όνομα* του video μου. Πήγα στην video και κοίταξα στα properties, στις λεπτομέρειες, τις *διαστάσεις (πλάτος ύψος)* του. Έβαλα τις διαστάσεις στο *size* ώστε το video να εμφανίζεται ομοιόμορφα από πίσω μου.


Τέλος, 

1. έτρεξα το αρχείο και άνοιξε η κάμερα, 
2. έφυγα τελείως από το οπτικό πεδίο της κάμερας, 
3. πάτησα κλικ με το ποντίκι στο παράθυρο της κάμερας και έτσι εμφανίστηκε το βίντεο. 
4. έπειτα μπήκα και εγώ στο οπτικό πεδίο της κάμερας και φαινόταν το βίντεο να παίζει από πίσω μου σε επανάληψη. 


![backgroundimage](https://user-images.githubusercontent.com/100956507/205702987-7a216b48-387a-4445-b24d-8a4cc9a6ee87.png)

![backvideo](https://user-images.githubusercontent.com/100956507/205703716-d3e28233-2f23-4d7f-b41f-faf532de5f0e.png)

![back2video](https://user-images.githubusercontent.com/100956507/205705028-e6af3df4-ad5d-4141-8f91-c5e3e97c61ee.png)


## Motion Detection

Αντέγραψα και επεξεργάστηκα το [Exercise 16-7](http://learningprocessing.com/exercises/chp16/exercise-16-07-track-motion) σε ένα νέο δικό μου αρχείο και το αποθήκευσα. Άλλαξα στον κώδικα το *`threshold, το smooth, το χρώμα - fill και το μέγεθος της έλλειψη - ellipse.`* Στην συνέχεια έτρεξα το προγράμμα και η έλλειψη ακολουθούσε το χέρι μου και γενικά τις κινήσεις μου.

![motion1](https://user-images.githubusercontent.com/100956507/205711684-4dbae8c5-30ae-4af7-89d1-8940179a2235.png)


## Background Substraction - Library use

Κατέβασα την βιβλιοθήκη OpenCV for Processing και άνοιξα το έτοιμο παράδειγμα BackgroundSubstraction. Έσβησα ότι εντολές αφορούσαν το βίντεο που είχε μέσα και πρόσθεσα στον κώδικα να ανοίγει η κάμερα του υπολογιστή από το παράδειγμα του Video Capture. Έπειτα, άλλαξα το χρώμα του περιγράμματος (stroke) και έτρεξα το αρχείο. Ανίχνευε τις κινήσεις μου, τοποθετώντας τες μέσα σε περιγράμματα και γραμμές.

![βιβλιοθηκη](https://user-images.githubusercontent.com/100956507/205720155-0010daef-e3f8-44bf-9822-fba0b28f544a.png)

![Capture](https://user-images.githubusercontent.com/100956507/199835802-c4565bb6-0f5b-4325-9bcd-fed6de8c702d.PNG)

![Screenshot (18)](https://user-images.githubusercontent.com/100956507/205722111-334c5fa1-a52d-4053-b718-68b8f1dd57f8.png)

![Screenshot (19)](https://user-images.githubusercontent.com/100956507/205722133-5c867ae1-17b8-485b-b117-d2d2525346b6.png)

![Screenshot (20)](https://user-images.githubusercontent.com/100956507/205722178-fbaac0a9-472c-4a03-8818-a0f53c8d8c58.png)


`Ποια είναι τα πλεονεκτήματα και μειονεκτήματα της έτοιμης βιβλιοθήκης έναντι του κώδικα από το πρώτο ερώτημα;`

* θΕΤΙΚΑ ΕΤΟΙΜΗΣ ΒΙΒΛΙΟΘΗΚΗΣ: 
  
1. Είναι σχεδιασμένη και κατάλληλη για εφαρμογές που γίνεται χρήση κάμερας σε πραγματικό χρόνο.
  
2. Αναγνωρίζει, εντοπίζει και αναλύει την κίνηση του σώματος και των αντικειμένων μέσω της κάμερας.
  
3. Τοποθετεί τις κινήσεις μου μέσα σε περιγράμματα και γραμμές.
  
* ΑΡΝΗΤΙΚΑ ΕΤΟΙΜΗΣ ΒΙΒΛΙΟΘΗΚΗΣ:

 1. Πρέπει να εγκαταστήσω την βιβλιοθήκη.
 
 2. Είναι για συγκεκριμένες εφαρμογές.
 
 3. Δεν μπορώ να κάνω μεγάλες αλλάγες στον κώδικα.


## Object Tracking

Αντέγραψα και επεξεργάστηκα το [Exercise 16-5](http://learningprocessing.com/exercises/chp16/exercise-16-05-snake-tracking) σε ένα νέο δικό μου αρχείο και το αποθήκευσα. Πήγα στην κλάση του `snake` και στο `χρώμα - fill έβαλα να εντοπίζει το χρώμα από την κάμερα`. Έτρεξα το προγράμμα και έδειξα στην κάμερα ένα μαρκαδόρο με πράσινο καπάκι, κλίκαρα πάνω στο πράσινο καπάκι και οι κύκλοι που εμφανίστηκαν στην οθόνη ήταν και αυτοί πράσινοι, ενώ στο σγουγγάρι που η επιφάνειά του ήταν χρώμα μπλέ, οι κύκλοι που εμφανίστηκαν στην οθόνη ήταν και αυτοί μπλε. Όσο κουνούσα τον μαρκαδόρο οι κύκλοι τον ακολουθούσαν δημιουργώντας μια "ουρά".

![track1](https://user-images.githubusercontent.com/100956507/205713105-ed647215-2b64-4d82-92db-b995e683d942.png)

![track2](https://user-images.githubusercontent.com/100956507/205713134-183cd61b-0533-42ed-bd1a-9baab5c50791.png)


`Σε σχέση με το παραδοσιακό ποντίκι ποια είναι τα πλεονεκτήματα και ποια τα μειονεκτήματα αυτής της τεχνικής ελέγχου ενός ή περισσότερων σημείων σε μια οθόνη?`

* θΕΤΙΚΑ ΤΕΧΝΙΚΗΣ ΕΛΕΓΧΟΥ:

1. Έχουμε την δυνατότητα να ελέγχουμε και να διαχειριζόμαστε τα στοιχεία εισόδου από απόσταση.

2. Μπορούμε να κάνουμε περίπλοκες κινήσεις με τα αντικείμενα που κρατάμε.

3. Το απότελεσμα είναι πιο ευχάριστο και διασκεδαστικό στον χρήστη καθώς υπάρχει άμεση διάδραση και αλληλεπίδραση.

* ΑΡΝΗΤΙΚΑ ΤΕΧΝΙΚΗΣ ΕΛΕΓΧΟΥ:

1. Χρειαζόμαστε κάμερα υψήλης ευκρίνειας. 

2. Εάν δεν διαθέτουμε καλή κάμερα το πρόγραμμα κολλάει και δείχνει καθυστερημένα τις κινήσεις στην οθόνη.

3. Το ποντίκι δίνει την δυνατότητα να κινούμε το αντικείμενο με μεγαλύτερη ακρίβεια στην οθόνη.


# 3rd Deliverable 

Έκανα εγκατάσταση της βιβλιοθήκης reacTIVision στο Processing και της εφαρμογής TUIO Simulator Processing.
Έτρεξα το παράδειγμα TUIO demo με τη χρήση του Simulator για να δω πως δουλεύει.

Έβαλα την εντολή `if (tobj.getSymbolID()==0)` το όποιο αντιπροσωπεύει το `fiducial 0`, έτσι έκανα και με τα υπόλοιπα βάζοντας αριθμούς 1,2,3 και 4. Οι κωδικοί fiducials αφορούν μια φωτογραφία που αποθήκευσα στο data και της έχω προσθέσει διάφορες μορφοποιήσεις.

* `Για id = Ι0 εμφανίζεται η είκονα στο κέντρο και μετακινείται όπου θέλω μέσα στον χώρο.`

![Screenshot (1)](https://user-images.githubusercontent.com/100956507/212179478-0970bf35-a3c7-49dd-8911-7e1b5c7690b6.png)

![Screenshot (2)](https://user-images.githubusercontent.com/100956507/212179414-fa5fb81a-ca7e-4641-adf9-700b0b509e0d.png)

![Screenshot (3)](https://user-images.githubusercontent.com/100956507/212179513-9b70ed6e-c93b-470f-9a14-5a3b4625dcfd.png)


* `Για id = I1 η εικόνα περιστρέφεται.`

![Screenshot (4)](https://user-images.githubusercontent.com/100956507/212179681-42519526-c4fc-4aa6-a171-1acf78d09682.png)


* `Για id = I2 κανει σμίκρυνση και μεγέθυνση της φωτογραφίας.`

![Screenshot (5)](https://user-images.githubusercontent.com/100956507/212179815-c62335ce-bdcc-4df7-826f-2752e3477b0b.png)

![Screenshot (6)](https://user-images.githubusercontent.com/100956507/212179837-73605df8-68b2-4ec6-842b-23ab474e986e.png)


* `Για id = I3 η φωτογραφία γίνεται πράσινη και αλλάζουν οι διάφορες αποχρώσεις του πράσινου όσο περιστρέφω το I3.`

![Screenshot (7)](https://user-images.githubusercontent.com/100956507/212180206-6a2dc8d2-7614-4ee1-a537-2432a3298fb6.png)


* `Για id = I4 η φωτογραφία γίνεται κόκκινη και αλλάζει η διάφάνεια της. Για να παίξει η εικόνα θα πρέπει να έχει αφαιρεθεί το Ι3 από μέσα.`

![Screenshot (8)](https://user-images.githubusercontent.com/100956507/212180327-91b31d8f-e897-4ba5-b321-b1e032f9a31e.png)


**Σε ποια φάση της σχεδίασης και ανάπτυξης του υλικό/λογισμικού της διάδρασης θα διαλέγατε την κανονική κάμερα ή τον προσομοιωτή?**

Η διαδικασία μέσω του simulator είναι πιο γρήγορη και εύκολη από την αναγνώριση των κωδικών fiducial μέσω κάμερας. Αυτό συμβαίνει γιατί στο simulator η διεπαφή με τον χρήστη είναι απλή και άμεση, αφού ο χρήστης τοποθετεί και επεξεργάζεται με το ποντίκι του τα fiducials και βλέπει ταυτόχρονα στην οθόνη τις διάφορες μορφοποιήσεις που γίνονται στην φωτογραφία. Η χρήση της κάμερας καθυστερεί τον χρήστη, αφού πρέπει να εντοπίσει και να διαβάσει τα τυπωμένα fiducials. O simulator βοηθά κατά την διάρκεια της πρωτοτυποποίησης γιατί ο χρήστης βλέπει, τεστάρει και διορθώνει τον κώδικα πριν τον προσαρμόσει σε ένα project.

# Bonus 


# Conclusions

Το πρώτο και το τρίτο παραδοτέο ήταν αρκετά απαιτητικά σε σχέση με το δεύτερο το όποιο ήταν αρκετά εύκολο. Το processing έχει έτοιμα παραδείγματα πράγμα που βοηθά να διαβάσω και να καταλάβω τον κώδικα. Είναι αρκετά ενδιαφέρον και ωραίο μάθημα το οποίο φέρνει κοντά την αλληλεπίδραση του χρήστη με τον υπολογιστή.

# Sources
